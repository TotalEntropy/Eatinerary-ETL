{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AUu7CT4B8nf-"
   },
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AUu7CT4B8nf-"
   },
   "outputs": [],
   "source": [
    "# Path to source JSON\n",
    "businessJson=os.path.join('sourceData', 'business.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AUu7CT4B8nf-"
   },
   "outputs": [],
   "source": [
    "# Path to Yelp food/restaurant categories csv\n",
    "yelpCategories=os.path.join('sourceData', 'yelpCategories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pd dataframe\n",
    "business_raw=pd.read_json(businessJson, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S4Hvn-gBXpaY"
   },
   "outputs": [],
   "source": [
    "# Select only the businesses in Ontario\n",
    "business_on=business_raw.loc[business_raw['state'] == 'ON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DodM3It9aKz7"
   },
   "outputs": [],
   "source": [
    "# Dropping any rows with blank values in these categories\n",
    "business=business_on.dropna(subset=['name', 'address', 'postal_code', 'city', 'state', 'latitude', 'longitude', 'attributes',\n",
    "                                               'categories', 'hours']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QuEHhPW8ewfY"
   },
   "outputs": [],
   "source": [
    "# Regex to fix spelling mistakes \n",
    "business.replace({'city': {'^AGINCOURT$': 'Agincourt',\n",
    "                           '^Bradford West Gwillimbury$': 'Bradford',\n",
    "                           '^East Ajax$': 'Ajax',\n",
    "                           '^Caledon.{,8}$': 'Caledon',\n",
    "                           '^East Gwil{1,2}imbury$': 'East Gwillimbury',\n",
    "                           '(?i)^.*icoke$': 'Etobicoke',\n",
    "                           '^.{,9}Toro?nto.{,9}$': 'Toronto',\n",
    "                           'Malton': 'Mississauga',\n",
    "                           '^.{,5}Missis{1,2}a?ua?g.{1,2}$': 'Mississauga',\n",
    "                           '^Regional Municipality of York$': 'North York',\n",
    "                           '(?i)^North.{0,2}York$': 'North York',\n",
    "                           '^York Regional Municipality$': 'York',\n",
    "                           '^Willowdale$': 'North York',\n",
    "                           '^North of Brampton$': 'Brampton',\n",
    "                           '(?i)^Oak.?ridges$': 'Oak Ridges',\n",
    "                           '^oakville$': 'Oakville',\n",
    "                           '(?i)^Richmond?.?Hill?$': 'Richmond Hill',\n",
    "                           '^.{,8}Scar.?bo?rough$': 'Scarborough',\n",
    "                           '^.{,11}Stouffville$': 'Stouffville',\n",
    "                           '(?i)^Thornhil{,2}$': 'Thornhill',\n",
    "                           '^.*Vaugh.{,3}$': 'Vaughan',\n",
    "                           '^Wh.?i.?by$': 'Whitby'}}, inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only taking these columns\n",
    "business=business.loc[:, ['name', 'address', 'postal_code', 'city', 'state', 'latitude', 'longitude','categories', 'stars', 'hours', 'attributes']]\n",
    "business.columns=['Name', 'Address', 'Postal_code', 'City', 'Province', 'Latitude', 'Longitude', 'Categories', 'Stars', 'Hours', 'Attributes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning the hours column in to a df\n",
    "hours_raw=json_normalize(data=business['Hours'])\n",
    "business.drop(columns='Hours', inplace=True)\n",
    "# hours_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling the hours column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganise columns\n",
    "hours_raw=hours_raw.loc[:,['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new df with opening and closing hours\n",
    "columnsHours=hours_raw.columns\n",
    "hours=hours_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through and split the columns\n",
    "for column in columnsHours:\n",
    "    hours[[f\"{column}_open\", f\"{column}_close\"]]=hours_raw[column].str.split('-', expand=True)\n",
    "hours.drop(columns=columnsHours, inplace=True)\n",
    "hours=hours.apply(lambda x: x.str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add hours column to the original DF\n",
    "business=business.join(hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling the categories column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning the Categories column in to a df and adding restaurant id\n",
    "category = business['Categories'].str.split(',', expand=True)\n",
    "business.drop(columns='Categories', inplace=True)\n",
    "category['Restaurant_id']=business.index\n",
    "category=pd.melt(category, id_vars='Restaurant_id', value_name='Category').drop(columns='variable').sort_values('Restaurant_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminating None categories\n",
    "category=category.loc[~category['Category'].isin([None])].reset_index(drop=True)\n",
    "category['Category'] = category['Category'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv with list of yelp categories\n",
    "foodCategories=pd.read_csv(yelpCategories)\n",
    "foodCategories['Category'] = foodCategories['Category'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only the categories from the list of yelp categories\n",
    "categoryFiltered=pd.DataFrame(category.loc[category['Category'].isin(foodCategories['Category'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out categories that don't apply\n",
    "categoryFiltered=categoryFiltered.loc[category['Category'].isin(['Acai Bowls', 'Afghan', 'African', 'Arabian', 'Argentine', 'Asian Fusion', 'Australian', 'Austrian', 'Bagels', 'Bangladeshi',\n",
    "                                                                   'Barbeque', 'Basque', 'Beer Bar', 'Beer Gardens', 'Beer Hall', 'Belgian', 'Bistros', 'Brasseries', 'Brazilian', 'Breakfast & Brunch',\n",
    "                                                                   'Brewpubs', 'British', 'Bubble Tea', 'Buffets', 'Burgers', 'Burmese', 'Cafes', 'Cajun/Creole', 'Cambodian', 'Cantonese', 'Caribbean',\n",
    "                                                                   'Champagne Bars', 'Cheese Shops', 'Cheesesteaks', 'Chicken Shop', 'Chicken Wings', 'Chinese', 'Chocolatiers & Shops',\n",
    "                                                                   'Cocktail Bars', 'Coffee & Tea', 'Colombian', 'Comfort Food', 'Creperies', 'Cuban', 'Cupcakes',\n",
    "                                                                   'Czech', 'Czech/Slovakian', 'Delicatessen', 'Delis', 'Desserts', 'Dim Sum', 'Diners', 'Dive Bars', 'Do-It-Yourself Food', 'Donairs',\n",
    "                                                                   'Egyptian', 'Ethical Grocery', 'Ethiopian', 'Falafel', 'Fast Food', 'Filipino', 'Fish & Chips', 'Fondue',\n",
    "                                                                   'Food Stands', 'Food Trucks', 'French', 'Fruits & Veggies', 'Gastropubs', 'Gelato', 'German', 'Gluten-Free', 'Greek', 'Hainan', 'Haitian',\n",
    "                                                                   'Hakka', 'Halal', 'Hawaiian', 'Himalayan/Nepalese', 'Hong Kong Style Cafe', 'Hot Dogs', 'Hot Pot', 'Hungarian', 'Iberian',\n",
    "                                                                   'Ice Cream & Frozen Yogurt', 'Imported Food', 'Indian', 'Indonesian', 'International', 'Internet Cafes', 'Irish', 'Irish Pub', 'Italian',\n",
    "                                                                   'Izakaya', 'Japanese', 'Japanese Sweets', 'Juice Bars & Smoothies', 'Kebab', 'Kombucha', 'Korean', 'Kosher', 'Laotian', 'Latin American',\n",
    "                                                                   'Lebanese', 'Live/Raw Food', 'Lounges', 'Macarons', 'Malaysian', 'Mauritius', 'Mediterranean', 'Mexican', 'Middle Eastern',\n",
    "                                                                   'Milkshake Bars', 'Minho', 'Modern European', 'Mongolian', 'Moroccan', 'Nicaraguan', 'Noodles', 'Pakistani', 'Pan Asian', 'Pasta Shops',\n",
    "                                                                   'Persian/Iranian', 'Peruvian', 'Pizza', 'Poke', 'Polish', 'Portuguese',\n",
    "                                                                   'Poutineries', 'Pubs', 'Ramen', 'Reunion', 'Russian', 'Salad', 'Salvadoran', 'Sandwiches', 'Scandinavian', 'Scottish', 'Seafood',\n",
    "                                                                   'Seafood Markets', 'Shanghainese', 'Shaved Ice', 'Shaved Snow', 'Singaporean', 'Slovakian', 'Smokehouse', 'Soul Food', 'Soup',\n",
    "                                                                   'South African', 'Southern', 'Spanish', 'Specialty Food', 'Sports Bars', 'Sri Lankan', 'Steakhouses', 'Street Vendors', 'Supper Clubs',\n",
    "                                                                   'Sushi Bars', 'Swiss Food', 'Syrian', 'Szechuan', 'Tacos', 'Taiwanese', 'Tapas Bars', 'Tapas/Small Plates', 'Tea Rooms', 'Tempura',\n",
    "                                                                   'Teppanyaki', 'Tex-Mex', 'Thai', 'Themed Cafes', 'Tiki Bars', 'Tonkatsu', 'Trinidadian', 'Turkish', 'Udon', 'Ukrainian', 'Vegan',\n",
    "                                                                   'Vegetarian', 'Venezuelan', 'Vietnamese', 'Waffles', 'Whiskey Bars', 'Wine Bars', 'Wraps'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of unique food categories\n",
    "uniqueCategories=categoryFiltered['Category'].unique()\n",
    "uniqueCategories.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all the values in categoryFiltered with the uniqueCategories index\n",
    "for index, value in enumerate(uniqueCategories):\n",
    "    categoryFiltered['Category'].replace(value, str(index), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all the categories to one string\n",
    "categoryPivot=categoryFiltered.pivot('Restaurant_id', 'Category', 'Category')\n",
    "categoryPivot['Categories']=categoryPivot.apply(lambda x: ','.join(x.dropna().values), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join categories column on business\n",
    "business=business.join(categoryPivot['Categories'], how='inner').reset_index(drop=True)\n",
    "business.rename(columns={'Categories':'Category_ids'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling the attributes column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning the Attributes column in to a df and adding restaurant id\n",
    "attributesRaw=json_normalize(business['Attributes'])\n",
    "attributesRaw['Restaurant_id']=business.index\n",
    "business.drop(columns='Attributes', inplace=True)\n",
    "attributes=attributesRaw.loc[attributesRaw['ByAppointmentOnly']!='True']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate unique categories for ambience \n",
    "ambienceCategories = attributesRaw['Ambience'].str.split(',', expand=True).replace(['{', '}', 'False', 'True', ':', \"'\"], '', regex=True).melt().drop(columns='variable')\n",
    "ambienceCategories=ambienceCategories.loc[~ambienceCategories['value'].isin(['None', 'NaN', None])].dropna()\n",
    "ambienceCategories=pd.DataFrame(ambienceCategories['value'].unique())\n",
    "ambienceCategories=ambienceCategories.sort_values(0).reset_index(drop=True)\n",
    "ambienceCategories=ambienceCategories.replace(\"'\", '', regex=True)\n",
    "ambienceCategories=ambienceCategories[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\brian\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\Users\\brian\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "# Generating boolean columns\n",
    "for value in ambienceCategories:\n",
    "    attributes[f'Ambience_{value}']=attributesRaw['Ambience'].str.contains(f\"{value}': True\")\n",
    "attributes.drop(columns='Ambience', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate unique categories for BusinessParking \n",
    "businessParking = attributesRaw['BusinessParking'].str.split(',', expand=True).replace(['{', '}', 'False', 'True', ':', \"'\"], '', regex=True).melt().drop(columns='variable')\n",
    "businessParking=businessParking.loc[~businessParking['value'].isin(['None', 'NaN', None])].dropna()\n",
    "businessParking=pd.DataFrame(businessParking['value'].unique())\n",
    "businessParking=businessParking.sort_values(0).reset_index(drop=True)\n",
    "businessParking=businessParking.replace([\"'\", ' '], '', regex=True)\n",
    "businessParking.drop(index=0, inplace=True)\n",
    "businessParking=businessParking[0].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\brian\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\Users\\brian\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "# Generating boolean columns \n",
    "for value in businessParking:\n",
    "    attributes[f'Parking_{value}']=attributesRaw['BusinessParking'].str.contains(f\"{value}': True\")\n",
    "attributes.drop(columns='BusinessParking', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate unique categories for GoodForMeal \n",
    "goodForMeal = attributesRaw['GoodForMeal'].str.split(',', expand=True).replace(['{', '}', 'False', 'True', ':', \"'\"], '', regex=True).melt().drop(columns='variable')\n",
    "goodForMeal=goodForMeal.loc[~goodForMeal['value'].isin(['None', 'NaN', None])].dropna()\n",
    "goodForMeal=pd.DataFrame(goodForMeal['value'].unique())\n",
    "goodForMeal=goodForMeal.sort_values(0).reset_index(drop=True)\n",
    "goodForMeal=goodForMeal.replace([\"'\", ' '], '', regex=True)\n",
    "goodForMeal.drop(index=0, inplace=True)\n",
    "goodForMeal=goodForMeal[0].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\brian\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\Users\\brian\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "# Generating boolean columns\n",
    "for value in goodForMeal:\n",
    "    attributes[f'Meal_{value}']=attributesRaw['GoodForMeal'].str.contains(f\"{value}': True\")\n",
    "attributes.drop(columns='GoodForMeal', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate unique categories for BestNights \n",
    "bestNights = attributesRaw['BestNights'].str.split(',', expand=True).replace(['{', '}', 'False', 'True', ':', \"'\"], '', regex=True).melt().drop(columns='variable')\n",
    "bestNights=bestNights.loc[~bestNights['value'].isin(['None', 'NaN', None])].dropna()\n",
    "bestNights=pd.DataFrame(bestNights['value'].unique())\n",
    "bestNights=bestNights.sort_values(0).reset_index(drop=True)\n",
    "bestNights=bestNights.replace([\"'\", ' '], '', regex=True)\n",
    "bestNights.drop(index=0, inplace=True)\n",
    "bestNights=bestNights[0].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\brian\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\Users\\brian\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "# Generating boolean columns\n",
    "for value in bestNights:\n",
    "    attributes[f'Best_night_{value}']=attributesRaw['BestNights'].str.contains(f\"{value}': True\")\n",
    "attributes.drop(columns='BestNights', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate unique categories for Alcohol \n",
    "alcohol=pd.DataFrame(attributesRaw['Alcohol'].unique()).dropna()\n",
    "alcohol=alcohol.replace([\"'\", ' '], '', regex=True)\n",
    "alcohol.drop(index=[0, 2, 3, 5, 7], inplace=True)\n",
    "alcohol=alcohol[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\brian\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Generate unique categories for Alcohol \n",
    "for value in alcohol:\n",
    "    attributes[f'Alcohol_{value}']=attributesRaw['Alcohol'].str.contains(value)\n",
    "attributes.drop(columns='Alcohol', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['halal', 'kosher', 'soy-free', 'vegan', 'vegetarian', 'dairy-free']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate unique categories for DietaryRestrictions \n",
    "dietaryRestrictions = attributesRaw['DietaryRestrictions'].str.split(',', expand=True).replace(['{', '}', 'False', 'True', ':', \"'\"], '', regex=True).melt().drop(columns='variable')\n",
    "dietaryRestrictions=dietaryRestrictions.loc[~dietaryRestrictions['value'].isin(['None', 'NaN', None])].dropna()\n",
    "dietaryRestrictions=pd.DataFrame(dietaryRestrictions['value'].unique())\n",
    "dietaryRestrictions=dietaryRestrictions.sort_values(0).reset_index(drop=True)\n",
    "dietaryRestrictions=dietaryRestrictions.replace([\"'\", ' '], '', regex=True)\n",
    "dietaryRestrictions.drop(index=0, inplace=True)\n",
    "dietaryRestrictions=dietaryRestrictions[0].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\brian\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\Users\\brian\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "# Generating boolean columns\n",
    "for value in dietaryRestrictions:\n",
    "    attributes[f'Dietary_Restrictions_{value}']=attributesRaw['DietaryRestrictions'].str.contains(f\"{value}': True\")\n",
    "attributes.drop(columns='DietaryRestrictions', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['background_music', 'dj', 'jukebox', 'karaoke', 'live', 'no_music', 'video']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate unique categories for Music \n",
    "music = attributesRaw['Music'].str.split(',', expand=True).replace(['{', '}', 'False', 'True', ':', \"'\"], '', regex=True).melt().drop(columns='variable')\n",
    "music=music.loc[~music['value'].isin(['None', 'NaN', None])].dropna()\n",
    "music=pd.DataFrame(music['value'].unique())\n",
    "music=music.sort_values(0).reset_index(drop=True)\n",
    "music=music.replace([\"'\", ' '], '', regex=True)\n",
    "music.drop(index=0, inplace=True)\n",
    "music=music[0].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\brian\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\Users\\brian\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "# Generating boolean columns\n",
    "for value in music:\n",
    "    attributes[f'Music_{value}']=attributesRaw['Music'].str.contains(f\"{value}': True\")\n",
    "attributes.drop(columns='Music', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['quiet', 'average', 'loud', 'very_loud']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate unique categories for NoiseLevel \n",
    "noiseLevel=pd.DataFrame(attributesRaw['NoiseLevel'].unique()).dropna().reset_index(drop=True)\n",
    "noiseLevel=noiseLevel.replace([\"'\", ' '], '', regex=True)\n",
    "noiseLevel.drop(index=[0, 1, 3, 6, 8], inplace=True)\n",
    "noiseLevel=noiseLevel[0].tolist()\n",
    "noiseLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\brian\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['NoiseLevel'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-99a808790c9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnoiseLevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mattributes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattributesRaw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'NoiseLevel'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mattributes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'NoiseLevel'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Users\\brian\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3938\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3939\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3940\u001b[1;33m                                            errors=errors)\n\u001b[0m\u001b[0;32m   3941\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3942\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[1;32mE:\\Users\\brian\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3778\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3779\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3780\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3782\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Users\\brian\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3810\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3811\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3812\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3813\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Users\\brian\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   4963\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4964\u001b[0m                 raise KeyError(\n\u001b[1;32m-> 4965\u001b[1;33m                     '{} not found in axis'.format(labels[mask]))\n\u001b[0m\u001b[0;32m   4966\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4967\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['NoiseLevel'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Generate unique categories for noiseLevel \n",
    "for value in noiseLevel:\n",
    "    attributes[f'Noise_{value}']=attributesRaw['NoiseLevel'].str.contains(value)\n",
    "attributes.drop(columns='NoiseLevel', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ucasual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dressy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>udressy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>uformal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>formal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0\n",
       "0  ucasual\n",
       "1   dressy\n",
       "2   casual\n",
       "3     None\n",
       "4  udressy\n",
       "5  uformal\n",
       "6   formal"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate unique categories for RestaurantsAttire \n",
    "restaurantsAttire=pd.DataFrame(attributesRaw['RestaurantsAttire'].unique()).dropna().reset_index(drop=True)\n",
    "restaurantsAttire=restaurantsAttire.replace([\"'\", ' '], '', regex=True).reset_index(drop=True)\n",
    "restaurantsAttire.drop(index=[0, 3, 4, 5], inplace=True)\n",
    "restaurantsAttire=restaurantsAttire[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\brian\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\Users\\brian\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "# Generate unique categories for RestaurantsAttire \n",
    "for value in restaurantsAttire:\n",
    "    attributes[f'Restaurants_Attire_{value}']=attributesRaw['RestaurantsAttire'].str.contains(value)\n",
    "attributes.drop(columns='RestaurantsAttire', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate unique categories for Smoking \n",
    "smoking=pd.DataFrame(attributesRaw['Smoking'].unique()).dropna().reset_index(drop=True)\n",
    "smoking=smoking.replace([\"'\", \"' '\", '.outdoor', '.yes'], ['', '', 'outdoor', 'yes'], regex=True).reset_index(drop=True)\n",
    "smoking.drop(index=[0, 2], inplace=True)\n",
    "smoking=smoking[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\brian\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Generating boolean columns\n",
    "for value in smoking:\n",
    "    attributes[f'Smoking_{value}']=attributesRaw['Smoking'].str.contains(f\"{value}': True\")\n",
    "attributes.drop(columns='Smoking', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes.drop(columns=['Caters', 'DriveThru', 'HairSpecializesIn', 'Open24Hours', 'RestaurantsDelivery'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AcceptsInsurance', 'AgesAllowed', 'BYOBCorkage', 'BikeParking',\n",
       "       'BusinessAcceptsBitcoin', 'BusinessAcceptsCreditCards',\n",
       "       'ByAppointmentOnly', 'Caters', 'CoatCheck', 'DogsAllowed', 'DriveThru',\n",
       "       'GoodForDancing', 'GoodForKids', 'HairSpecializesIn', 'HappyHour',\n",
       "       'HasTV', 'Open24Hours', 'OutdoorSeating', 'RestaurantsCounterService',\n",
       "       'RestaurantsDelivery', 'RestaurantsGoodForGroups',\n",
       "       'RestaurantsPriceRange2', 'RestaurantsReservations',\n",
       "       'RestaurantsTableService', 'RestaurantsTakeOut', 'Smoking',\n",
       "       'WheelchairAccessible', 'WiFi', 'Restaurant_id', 'Ambience_casual',\n",
       "       'Ambience_classy', 'Ambience_divey', 'Ambience_hipster',\n",
       "       'Ambience_intimate', 'Ambience_romantic', 'Ambience_touristy',\n",
       "       'Ambience_trendy', 'Ambience_upscale', 'Parking_garage', 'Parking_lot',\n",
       "       'Parking_street', 'Parking_valet', 'Parking_validated',\n",
       "       'Meal_breakfast', 'Meal_brunch', 'Meal_dinner', 'Meal_latenight',\n",
       "       'Meal_lunch', 'Meal_dessert', 'Best_night_saturday',\n",
       "       'Best_night_sunday', 'Best_night_thursday', 'Best_night_tuesday',\n",
       "       'Best_night_wednesday', 'Best_night_monday', 'beer_and_wine',\n",
       "       'full_bar', 'Dietary_Restrictions_halal', 'Dietary_Restrictions_kosher',\n",
       "       'Dietary_Restrictions_soy-free', 'Dietary_Restrictions_vegan',\n",
       "       'Dietary_Restrictions_vegetarian', 'Dietary_Restrictions_dairy-free',\n",
       "       'Music_background_music', 'Music_dj', 'Music_jukebox', 'Music_karaoke',\n",
       "       'Music_live', 'Music_no_music', 'Music_video', 'quiet', 'average',\n",
       "       'loud', 'very_loud', 'dressy', 'casual', 'formal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"u'no'\", \"u'free'\", \"'no'\", nan, \"'free'\", \"u'paid'\", \"'paid'\",\n",
       "       'None'], dtype=object)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes['WiFi'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO check if all the boolean columns have values in them by running attributes['x'].sum()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ETL.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
