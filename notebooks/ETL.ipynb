{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AUu7CT4B8nf-"
   },
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AUu7CT4B8nf-"
   },
   "outputs": [],
   "source": [
    "# Path to source JSON\n",
    "businessJson=os.path.join('sourceData', 'business.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AUu7CT4B8nf-"
   },
   "outputs": [],
   "source": [
    "# Path to Yelp food/restaurant categories csv\n",
    "yelpCategories=os.path.join('sourceData', 'yelpCategories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pd dataframe\n",
    "business_raw=pd.read_json(businessJson, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S4Hvn-gBXpaY"
   },
   "outputs": [],
   "source": [
    "# Select only the businesses in Ontario\n",
    "business_on=business_raw.loc[business_raw['state'] == 'ON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DodM3It9aKz7"
   },
   "outputs": [],
   "source": [
    "# Dropping any rows with blank values in these categories\n",
    "business_on=business_on.dropna(subset=['name', 'address', 'postal_code', 'city', 'state', 'latitude', 'longitude', 'attributes',\n",
    "                                               'categories', 'hours']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QuEHhPW8ewfY"
   },
   "outputs": [],
   "source": [
    "# Regex to fix spelling mistakes \n",
    "business_on.replace({'city': {'^AGINCOURT$': 'Agincourt',\n",
    "                           '^Bradford West Gwillimbury$': 'Bradford',\n",
    "                           '^East Ajax$': 'Ajax',\n",
    "                           '^Caledon.{,8}$': 'Caledon',\n",
    "                           '^East Gwil{1,2}imbury$': 'East Gwillimbury',\n",
    "                           '(?i)^.*icoke$': 'Etobicoke',\n",
    "                           '^.{,9}Toro?nto.{,9}$': 'Toronto',\n",
    "                           'Malton': 'Mississauga',\n",
    "                           '^.{,5}Missis{1,2}a?ua?g.{1,2}$': 'Mississauga',\n",
    "                           '^Regional Municipality of York$': 'North York',\n",
    "                           '(?i)^North.{0,2}York$': 'North York',\n",
    "                           '^York Regional Municipality$': 'York',\n",
    "                           '^Willowdale$': 'North York',\n",
    "                           '^North of Brampton$': 'Brampton',\n",
    "                           '(?i)^Oak.?ridges$': 'Oak Ridges',\n",
    "                           '^oakville$': 'Oakville',\n",
    "                           '(?i)^Richmond?.?Hill?$': 'Richmond Hill',\n",
    "                           '^.{,8}Scar.?bo?rough$': 'Scarborough',\n",
    "                           '^.{,11}Stouffville$': 'Stouffville',\n",
    "                           '(?i)^Thornhil{,2}$': 'Thornhill',\n",
    "                           '^.*Vaugh.{,3}$': 'Vaughan',\n",
    "                           '^Wh.?i.?by$': 'Whitby'}}, inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "business=business_on.loc[business_on['city'].isin(['Unionville', 'Bolton', 'York', 'Bradford', 'Concord', 'East York', 'Stouffville',\n",
    "                                                   'Woodbridge', 'Aurora', 'Ajax', 'Whitby', 'Pickering', 'Thornhill', 'Newmarket',\n",
    "                                                   'Oakville', 'Etobicoke', 'North York', 'Scarborough', 'Vaughan', 'Richmond Hill',\n",
    "                                                   'Brampton', 'Markham', 'Mississauga', 'Toronto'])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only taking these columns\n",
    "business=business.loc[:, ['name', 'address', 'postal_code', 'city', 'state', 'latitude', 'longitude','categories', 'stars', 'hours','attributes']]\n",
    "business.columns=['Name', 'Address', 'Postal_code', 'City', 'Province', 'Latitude', 'Longitude', 'Categories', 'Stars', 'Hours', 'Attributes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning the hours column in to a df\n",
    "hours_raw=json_normalize(data=business['Hours'])\n",
    "business.drop(columns='Hours', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling the hours column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganise columns\n",
    "hours_raw=hours_raw.loc[:,['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new df with opening and closing hours\n",
    "columnsHours=hours_raw.columns\n",
    "hours=hours_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through and split the columns\n",
    "for column in columnsHours:\n",
    "    hours[[f\"{column}_open\", f\"{column}_close\"]]=hours_raw[column].str.split('-', expand=True)\n",
    "hours.drop(columns=columnsHours, inplace=True)\n",
    "hours=hours.apply(lambda x: x.str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add hours column to the original DF\n",
    "business=business.join(hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling the categories column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning the Categories column in to a df and adding restaurant id\n",
    "category = business['Categories'].str.split(',', expand=True)\n",
    "business.drop(columns='Categories', inplace=True)\n",
    "category['Restaurant_id']=business.index\n",
    "category=pd.melt(category, id_vars='Restaurant_id', value_name='Category').drop(columns='variable').sort_values('Restaurant_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminating None categories\n",
    "category=category.loc[~category['Category'].isin([None])].reset_index(drop=True)\n",
    "category['Category'] = category['Category'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv with list of yelp categories\n",
    "foodCategories=pd.read_csv(yelpCategories)\n",
    "foodCategories['Category'] = foodCategories['Category'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only the categories from the list of yelp categories\n",
    "categoryFiltered=pd.DataFrame(category.loc[category['Category'].isin(foodCategories['Category'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out categories that don't apply\n",
    "categoryFiltered=categoryFiltered.loc[category['Category'].isin(['Acai Bowls', 'Afghan', 'African', 'Arabian', 'Argentine', 'Asian Fusion', 'Australian', 'Austrian', 'Bagels', 'Bangladeshi',\n",
    "                                                                   'Barbeque', 'Basque', 'Beer Bar', 'Beer Gardens', 'Beer Hall', 'Belgian', 'Bistros', 'Brasseries', 'Brazilian', 'Breakfast & Brunch',\n",
    "                                                                   'Brewpubs', 'British', 'Bubble Tea', 'Buffets', 'Burgers', 'Burmese', 'Cafes', 'Cajun/Creole', 'Cambodian', 'Cantonese', 'Caribbean',\n",
    "                                                                   'Champagne Bars', 'Cheese Shops', 'Cheesesteaks', 'Chicken Shop', 'Chicken Wings', 'Chinese', 'Chocolatiers & Shops',\n",
    "                                                                   'Cocktail Bars', 'Coffee & Tea', 'Colombian', 'Comfort Food', 'Creperies', 'Cuban', 'Cupcakes',\n",
    "                                                                   'Czech', 'Czech/Slovakian', 'Delicatessen', 'Delis', 'Desserts', 'Dim Sum', 'Diners', 'Dive Bars', 'Do-It-Yourself Food', 'Donairs',\n",
    "                                                                   'Egyptian', 'Ethical Grocery', 'Ethiopian', 'Falafel', 'Fast Food', 'Filipino', 'Fish & Chips', 'Fondue',\n",
    "                                                                   'Food Stands', 'Food Trucks', 'French', 'Fruits & Veggies', 'Gastropubs', 'Gelato', 'German', 'Gluten-Free', 'Greek', 'Hainan', 'Haitian',\n",
    "                                                                   'Hakka', 'Halal', 'Hawaiian', 'Himalayan/Nepalese', 'Hong Kong Style Cafe', 'Hot Dogs', 'Hot Pot', 'Hungarian', 'Iberian',\n",
    "                                                                   'Ice Cream & Frozen Yogurt', 'Imported Food', 'Indian', 'Indonesian', 'International', 'Internet Cafes', 'Irish', 'Irish Pub', 'Italian',\n",
    "                                                                   'Izakaya', 'Japanese', 'Japanese Sweets', 'Juice Bars & Smoothies', 'Kebab', 'Kombucha', 'Korean', 'Kosher', 'Laotian', 'Latin American',\n",
    "                                                                   'Lebanese', 'Live/Raw Food', 'Lounges', 'Macarons', 'Malaysian', 'Mauritius', 'Mediterranean', 'Mexican', 'Middle Eastern',\n",
    "                                                                   'Milkshake Bars', 'Minho', 'Modern European', 'Mongolian', 'Moroccan', 'Nicaraguan', 'Noodles', 'Pakistani', 'Pan Asian', 'Pasta Shops',\n",
    "                                                                   'Persian/Iranian', 'Peruvian', 'Pizza', 'Poke', 'Polish', 'Portuguese',\n",
    "                                                                   'Poutineries', 'Pubs', 'Ramen', 'Reunion', 'Russian', 'Salad', 'Salvadoran', 'Sandwiches', 'Scandinavian', 'Scottish', 'Seafood',\n",
    "                                                                   'Seafood Markets', 'Shanghainese', 'Shaved Ice', 'Shaved Snow', 'Singaporean', 'Slovakian', 'Smokehouse', 'Soul Food', 'Soup',\n",
    "                                                                   'South African', 'Southern', 'Spanish', 'Specialty Food', 'Sports Bars', 'Sri Lankan', 'Steakhouses', 'Street Vendors', 'Supper Clubs',\n",
    "                                                                   'Sushi Bars', 'Swiss Food', 'Syrian', 'Szechuan', 'Tacos', 'Taiwanese', 'Tapas Bars', 'Tapas/Small Plates', 'Tea Rooms', 'Tempura',\n",
    "                                                                   'Teppanyaki', 'Tex-Mex', 'Thai', 'Themed Cafes', 'Tiki Bars', 'Tonkatsu', 'Trinidadian', 'Turkish', 'Udon', 'Ukrainian', 'Vegan',\n",
    "                                                                   'Vegetarian', 'Venezuelan', 'Vietnamese', 'Waffles', 'Whiskey Bars', 'Wine Bars', 'Wraps'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of unique food categories\n",
    "uniqueCategories=categoryFiltered['Category'].unique()\n",
    "uniqueCategories.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all the values in categoryFiltered with the uniqueCategories index\n",
    "for index, value in enumerate(uniqueCategories):\n",
    "    categoryFiltered['Category'].replace(value, str(index), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all the categories to one string\n",
    "categoryPivot=categoryFiltered.pivot('Restaurant_id', 'Category', 'Category')\n",
    "categoryPivot['Categories']=categoryPivot.apply(lambda x: ','.join(x.dropna().values), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join categories column on business\n",
    "business=business.join(categoryPivot['Categories'], how='inner').reset_index(drop=True)\n",
    "business.rename(columns={'Categories':'Category_ids'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling the attributes column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning the Attributes column in to a df and adding restaurant id\n",
    "attributesRaw=json_normalize(business['Attributes'])\n",
    "business.drop(columns='Attributes', inplace=True)\n",
    "attributes=attributesRaw.fillna('')\n",
    "attributes['Restaurant_id']=business.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate unique categories for ambience \n",
    "ambienceCategories=attributesRaw['Ambience'].str.split(',', expand=True).replace(['{', '}', 'False', 'True', ':', \"'\", ' '], '', regex=True).melt().dropna().drop(columns='variable')\n",
    "ambienceCategories=ambienceCategories.loc[~ambienceCategories['value'].isin(['None'])]\n",
    "ambienceCategories=ambienceCategories['value'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating boolean columns for ambience\n",
    "for value in ambienceCategories:\n",
    "    attributes[f'Ambience_{value}']=attributes['Ambience'].str.contains(f\"{value}': True\")\n",
    "attributes.drop(columns='Ambience', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate unique categories for BusinessParking\n",
    "businessParking = attributesRaw['BusinessParking'].str.split(',', expand=True).replace(['{', '}', 'False', 'True', ':', \"'\", ' '], '', regex=True).melt().dropna().drop(columns='variable')\n",
    "businessParking=businessParking.loc[~businessParking['value'].isin(['None', ''])]\n",
    "businessParking=businessParking['value'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating boolean columns for BusinessParking\n",
    "for value in businessParking:\n",
    "    attributes[f'Parking_{value}']=attributes['BusinessParking'].str.contains(f\"{value}': True\")\n",
    "attributes.drop(columns='BusinessParking', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate unique categories for GoodForMeal\n",
    "goodForMeal = attributesRaw['GoodForMeal'].str.split(',', expand=True).replace(['{', '}', 'False', 'True', ':', \"'\", ' '], '', regex=True).melt().drop(columns='variable').dropna()\n",
    "goodForMeal=goodForMeal.loc[~goodForMeal['value'].isin(['None', ''])]\n",
    "goodForMeal=goodForMeal['value'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating boolean columns for GoodForMeal\n",
    "for value in goodForMeal:\n",
    "    attributes[f'Meal_{value}']=attributes['GoodForMeal'].str.contains(f\"{value}': True\")\n",
    "attributes.drop(columns='GoodForMeal', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate unique categories for BestNights\n",
    "bestNights = attributesRaw['BestNights'].str.split(',', expand=True).replace(['{', '}', 'False', 'True', ':', \"'\", ' '], '', regex=True).melt().drop(columns='variable').dropna()\n",
    "bestNights=bestNights.loc[~bestNights['value'].isin([''])]\n",
    "bestNights=bestNights['value'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating boolean columns for BestNights\n",
    "for value in bestNights:\n",
    "    attributes[f'Best_night_{value}']=attributes['BestNights'].str.contains(f\"{value}': True\")\n",
    "attributes.drop(columns='BestNights', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate unique categories for Alcohol\n",
    "alcohol=pd.DataFrame(attributesRaw['Alcohol'].unique()).dropna()\n",
    "alcohol=alcohol.replace([\"'\", ' '], '', regex=True)\n",
    "alcohol=alcohol.loc[~alcohol[0].isin(['none', 'ufull_bar', 'unone', 'ubeer_and_wine', 'None'])]\n",
    "alcohol=alcohol[0].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate unique categories for Alcohol\n",
    "for value in alcohol:\n",
    "    attributes[f'Alcohol_{value}']=attributes['Alcohol'].str.contains(value)\n",
    "attributes.drop(columns='Alcohol', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate unique categories for DietaryRestrictions \n",
    "dietaryRestrictions = attributes['DietaryRestrictions'].str.split(',', expand=True).replace(['{', '}', 'False', 'True', ':', \"'\", ' '], '',\n",
    "                                                                                               regex=True).melt().drop(columns='variable').dropna()\n",
    "dietaryRestrictions=dietaryRestrictions.loc[~dietaryRestrictions['value'].isin(['None', ''])]\n",
    "dietaryRestrictions=dietaryRestrictions['value'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating boolean columns\n",
    "for value in dietaryRestrictions:\n",
    "    attributes[f'Dietary_Restrictions_{value}']=attributes['DietaryRestrictions'].str.contains(f\"{value}': True\")\n",
    "attributes.drop(columns='DietaryRestrictions', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate unique categories for Music \n",
    "music = attributesRaw['Music'].str.split(',', expand=True).replace(['{', '}', 'False', 'True', ':', \"'\", ' '], '', regex=True).melt().drop(columns='variable').dropna()\n",
    "music=music.loc[~music['value'].isin(['None', ''])]\n",
    "music=music['value'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating boolean columns\n",
    "for value in music:\n",
    "    attributes[f'Music_{value}']=attributes['Music'].str.contains(f\"{value}': True\")\n",
    "attributes.drop(columns='Music', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate unique categories for NoiseLevel \n",
    "noiseLevel=pd.DataFrame(attributesRaw['NoiseLevel'].unique()).dropna()\n",
    "noiseLevel=noiseLevel.replace([\"'\", ' '], '', regex=True)\n",
    "noiseLevel=noiseLevel.loc[~noiseLevel[0].isin(['None', 'uloud', 'uaverage', 'uquiet', 'uvery_loud'])]\n",
    "noiseLevel=noiseLevel[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate unique categories for noiseLevel \n",
    "for value in noiseLevel:\n",
    "    attributes[f'Noise_{value}']=attributes['NoiseLevel'].str.contains(value)\n",
    "attributes.drop(columns='NoiseLevel', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate unique categories for RestaurantsAttire \n",
    "restaurantsAttire=pd.DataFrame(attributesRaw['RestaurantsAttire'].unique()).dropna()\n",
    "restaurantsAttire=restaurantsAttire.replace([\"'\", ' '], '', regex=True)\n",
    "restaurantsAttire=restaurantsAttire.loc[~restaurantsAttire[0].isin(['ucasual', 'None', 'udressy', 'uformal'])]\n",
    "restaurantsAttire=restaurantsAttire[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate unique categories for RestaurantsAttire \n",
    "for value in restaurantsAttire:\n",
    "    attributes[f'Restaurants_Attire_{value}']=attributes['RestaurantsAttire'].str.contains(value)\n",
    "attributes.drop(columns='RestaurantsAttire', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate unique categories for Smoking \n",
    "smoking=pd.DataFrame(attributesRaw['Smoking'].unique()).dropna()\n",
    "smoking=smoking.replace([\"'\", \"' '\", '.outdoor', '.yes', '.no'], ['', '', 'outdoor', 'yes', 'no'], regex=True)\n",
    "smoking=smoking.loc[~smoking[0].isin(['None'])]\n",
    "smoking=smoking[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating Smoking boolean columns\n",
    "for value in smoking:\n",
    "    attributes[f'Smoking_{value}']=attributes['Smoking'].str.contains(f\"{value}': True\")\n",
    "attributes.drop(columns='Smoking', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to boolean\n",
    "attributes.replace({'AgesAllowed':{'':False, \"u'19plus'\":True},\n",
    "                    'BYOBCorkage':{'':False, \"u'yes_corkage'\":True},\n",
    "                    'BikeParking':{'False':False, 'None':False, '':False, 'True':True},\n",
    "                    'BusinessAcceptsCreditCards':{'False':False, 'None':False, '':False, 'True':True},\n",
    "                    'CoatCheck':{'False':False, 'None':False, '':False, 'True':True},\n",
    "                    'DogsAllowed':{'False':False, 'None':False, '':False, 'True':True},\n",
    "                    'GoodForDancing':{'False':False, 'None':False, '':False, 'True':True},\n",
    "                    'GoodForKids':{'False':False, 'None':False, '':False, 'True':True},\n",
    "                    'HappyHour':{'False':False, 'None':False, '':False, 'True':True},\n",
    "                    'HasTV':{'False':False, 'None':False, '':False, 'True':True},\n",
    "                    'OutdoorSeating':{'False':False, 'None':False, '':False, 'True':True},\n",
    "                    'RestaurantsCounterService':{'True':True, '':False},\n",
    "                    'RestaurantsGoodForGroups':{'False':False, 'None':False, '':False, 'True':True},\n",
    "                    'RestaurantsPriceRange2':{'None':np.nan},\n",
    "#                     'RestaurantsPriceRange2':{'':0, 'None':0},\n",
    "                    'RestaurantsTableService':{'False':False, 'None':False, '':False, 'True':True},\n",
    "                    'RestaurantsTakeOut':{'False':False, 'None':False, '':False, 'True':True},\n",
    "                    'WheelchairAccessible':{'False':False, 'None':False, '':False, 'True':True}}, inplace=True)\n",
    "\n",
    "# Convert pricing column to int\n",
    "attributes['RestaurantsPriceRange2']=pd.to_numeric(attributes['RestaurantsPriceRange2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename AgesAllowed to Over_19\n",
    "attributes.rename(columns={'AgesAllowed':'Over_19'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "attributes.drop(columns=['AcceptsInsurance', 'BusinessAcceptsBitcoin', 'Caters', 'DriveThru', 'HairSpecializesIn', 'Open24Hours',\n",
    "                         'RestaurantsDelivery', 'RestaurantsReservations', 'WiFi'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by restaurants that require appointments\n",
    "attributes=attributes.loc[attributes['ByAppointmentOnly']!='True']\n",
    "attributes.drop(columns='ByAppointmentOnly', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the master table with the attributes table\n",
    "business=business.join(attributes, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String, Float\n",
    "from sourceData.config import conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'MySQLdb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-d13d1a654c7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Create engine\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'mysql://{conn}'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mecho\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Users\\brian\\Anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\__init__.py\u001b[0m in \u001b[0;36mcreate_engine\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    421\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"strategy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_strategy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstrategies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrategies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Users\\brian\\Anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\strategies.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, name_or_url, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m                     \u001b[0mdbapi_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpop_kwarg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[0mdbapi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdialect_cls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdbapi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdbapi_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0mdialect_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"dbapi\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdbapi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Users\\brian\\Anaconda3\\lib\\site-packages\\sqlalchemy\\dialects\\mysql\\mysqldb.py\u001b[0m in \u001b[0;36mdbapi\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdbapi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m__import__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"MySQLdb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdo_ping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdbapi_connection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'MySQLdb'"
     ]
    }
   ],
   "source": [
    "# Create engine\n",
    "## need to run pip install mysql-python\n",
    "## need to run pip install misaka\n",
    "engine = create_engine(f'mysql+mysqldb://{conn}', echo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating sql database and tables for the restaurants and the unique categories\n",
    "business.to_sql(Restaurant, conn, if_exists='replace', index_label='Restaurant_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta = MetaData()\n",
    "\n",
    "# Movie = Table(\n",
    "#     'Movie', meta,\n",
    "#     Column('Title', String(100)),\n",
    "#     Column('Year', Integer),\n",
    "#     Column('Director', String(100)),\n",
    "#     Column('Origin/Ethnicity', String(100)),\n",
    "#     Column('Language', String(100)), \n",
    "#     Column('Cast', String(100)),\n",
    "#     Column('Colour', String(100)),\n",
    "#     Column('Duration', Integer),\n",
    "#     Column('Budget', Integer),\n",
    "#     Column('Gross', Integer),\n",
    "#     Column('Genres', String(100)),\n",
    "#     Column('Plot', String(1000)),\n",
    "#     Column('Plot_keywords', String(100)),\n",
    "#     Column('Aspect_ratio', Float)\n",
    "# )\n",
    "\n",
    "# meta.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_sql(name='movie', con=engine, if_exists='replace', index=True)\n",
    "# pd.read_sql_query('select * from movie', con=engine).head()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ETL.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
